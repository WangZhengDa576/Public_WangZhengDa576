---
title: "02 CatBoost: Insight Edge"
output: html_document
date: "2025-07-30"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Load Packages

```{r}
# Install (if needed)
# install.packages("devtools")
# devtools::install_github("catboost/catboost", subdir = "catboost/R-package")
library(catboost)
library(dplyr)
library(MLmetrics)
```

## 2. Load and Prepare Training Data

```{r}
# Set working directory and read
setwd("C:/Users/Valerie/OneDrive - Singapore University of Technology and Design/00 YJ personal/00 Academics/00 Term 5 Mods/40.016 The Analytics Edge/00 1D Project/Submissions")
rm(list=ls())
train <- read.csv("train2024.csv")

# Drop unnecessary columns
smallertrain <- subset(train, select = -c(Case, No, Task, segment, year, miles, night, ppark, gender, age, educ, region, Urb, income))
smallesttrain <- subset(smallertrain, select = -c(milesa, nighta, agea, incomea))

colnames(smallesttrain)[1:91] <- paste0("X", 1:91)

# Convert one-hot target to integer label (0-based)
smallesttrain$label <- apply(smallesttrain[, c("Ch1", "Ch2", "Ch3", "Ch4")], 1, function(row) which(row == 1) - 1)

# Train-validation split
set.seed(42)
train_index <- sample(1:nrow(smallesttrain), 0.7 * nrow(smallesttrain))
train_data <- smallesttrain[train_index, ]
valid_data <- smallesttrain[-train_index, ]
```

## 3. Create CatBoost Pools

```{r}
predictor_columns <- paste0("X", 1:91)

# Assuming train_data and valid_data already exist
train_data[, predictor_columns] <- lapply(train_data[, predictor_columns], as.numeric)
valid_data[, predictor_columns] <- lapply(valid_data[, predictor_columns], as.numeric)

# Now create full_data only after train_data and valid_data are preprocessed
train_data$choice <- NULL
full_data <- rbind(train_data, valid_data)
full_data[, predictor_columns] <- lapply(full_data[, predictor_columns], as.numeric)

# Load and prepare test data
test_raw <- read.csv("test2024.csv")
smallertest <- subset(test_raw, select = -c(Case, No, Task, segment, year, miles, night, ppark, gender, age, educ, region, Urb, income))
smallesttest <- subset(smallertest, select = -c(milesa, nighta, agea, incomea))
colnames(smallesttest)[1:91] <- paste0("X", 1:91)
smallesttest[, predictor_columns] <- lapply(smallesttest[, predictor_columns], as.numeric)

# Sanity check: ensure all required columns are present
stopifnot(all(predictor_columns %in% colnames(smallesttest)))

# Create catboost pools
pool_train <- catboost.load_pool(data = train_data[, predictor_columns], label = train_data$label)
pool_valid <- catboost.load_pool(data = valid_data[, predictor_columns], label = valid_data$label)
pool_full  <- catboost.load_pool(data = full_data[, predictor_columns], label = full_data$label)
pool_test  <- catboost.load_pool(data = smallesttest[, predictor_columns])

```

## 3.5 Cross-Validation to Find Best Iteration

``` {r}
# Create pool on full training data (train + valid)
cv_pool <- catboost.load_pool(data = full_data[, predictor_columns], label = full_data$label)

cv_params <- list(
  loss_function = "MultiClass",
  eval_metric = "MultiClass",
  iterations = 3333,
  learning_rate = 0.015,
  depth = 6,
  l2_leaf_reg = 5,
  random_strength = 1,
  bagging_temperature = 1,
  random_seed = 42,
  od_type = "Iter",
  od_wait = 20,
  logging_level = "Silent"
)

cv_result <- catboost.cv(
  params = cv_params,
  pool = cv_pool,
  fold_count = 5,
  type = "Classical",
  partition_random_seed = 42,
)

best_iter_cv <- which.min(cv_result$test.MultiClass.mean)
cat(sprintf("Best iteration from CV: %d\n", best_iter_cv))
```

## 4. Train CatBoost with Early Stopping

``` {r}
params <- list(
  loss_function = "MultiClass",
  eval_metric = "MultiClass",
  iterations = 3333,
  learning_rate = 0.015,
  l2_leaf_reg = 5,
  random_strength = 1,
  bagging_temperature = 1,
  random_seed = 42,
  od_type = "Iter",
  od_wait = 20,
  verbose = 0
)

model <- catboost.train(
  learn_pool = pool_train,
  test_pool = pool_valid,
  params = params
)

# Extract the best number of iterations (trees)
best_iter <- model$tree_count
cat(sprintf("Best iteration (early stopping): %d\n", best_iter))
```

## 5. LogLoss on Validation Set

``` {r}
# Get predicted probabilities
val_probs <- catboost.predict(model, pool_valid, prediction_type = "Probability")

# One-hot encode actual labels
true_labels <- valid_data$label
true_matrix <- matrix(0, nrow = length(true_labels), ncol = 4)
true_matrix[cbind(1:length(true_labels), true_labels + 1)] <- 1

# Clip probabilities
eps <- 1e-15
val_probs <- pmin(pmax(val_probs, eps), 1 - eps)

# Compute log loss
logloss <- -mean(rowSums(true_matrix * log(val_probs)))
cat(sprintf("LogLoss on Validation Set: %.5f\n", logloss))
```

##5.5 Feature Importance Filtering

```{r}
importance_vals <- catboost.get_feature_importance(model, pool_train, type = "PredictionValuesChange")

importance_df <- data.frame(
  Feature = predictor_columns,
  Importance = importance_vals
)

importance_df <- importance_df[order(-importance_df$Importance), ]
print(head(importance_df, 10))

selected_features <- importance_df$Feature[importance_df$Importance > 0.01]
cat(sprintf("Selected %d features based on importance threshold.\n", length(selected_features)))

train_data_reduced <- train_data[, c(selected_features, "label")]
valid_data_reduced <- valid_data[, c(selected_features, "label")]

pool_train_reduced <- catboost.load_pool(data = train_data_reduced[, selected_features], label = train_data_reduced$label)
pool_valid_reduced <- catboost.load_pool(data = valid_data_reduced[, selected_features], label = valid_data_reduced$label)

model_reduced <- catboost.train(
  learn_pool = pool_train_reduced,
  test_pool = pool_valid_reduced,
  params = list(
    loss_function = "MultiClass",
    eval_metric = "MultiClass",
    iterations = best_iter,
    learning_rate = 0.015,
    depth = 6,
    l2_leaf_reg = 5,
    random_strength = 1,
    bagging_temperature = 1,
    random_seed = 42,
    verbose = 0
  )
)

val_probs_reduced <- catboost.predict(model_reduced, pool_valid_reduced, prediction_type = "Probability")

true_labels <- valid_data_reduced$label
true_matrix <- matrix(0, nrow = length(true_labels), ncol = 4)
true_matrix[cbind(1:length(true_labels), true_labels + 1)] <- 1

val_probs_reduced <- pmin(pmax(val_probs_reduced, eps), 1 - eps)

logloss_reduced <- -mean(rowSums(true_matrix * log(val_probs_reduced)))
cat(sprintf("LogLoss on Validation Set with Reduced Features: %.5f\n", logloss_reduced))
```

## 6. Retrain on Full Data with Selected Features (Feature Importance Filtering)

```{r}
# Remove 'choice' column if present, as a safety check
if ("choice" %in% colnames(full_data)) full_data$choice <- NULL

# Subset to selected features + label only
full_data_reduced <- full_data[, c(selected_features, "label")]

# Create CatBoost pool with filtered features
pool_full_reduced <- catboost.load_pool(
  data = full_data_reduced[, selected_features],
  label = full_data_reduced$label
)

# Train final model with best iteration found from CV (or previous step)
final_model_reduced <- catboost.train(
  learn_pool = pool_full_reduced,
  params = list(
    loss_function = "MultiClass",
    eval_metric = "MultiClass",
    iterations = best_iter_cv,  # from your CV step
    learning_rate = 0.015,
    depth = 6,
    l2_leaf_reg = 5,
    random_strength = 1,
    bagging_temperature = 1,
    random_seed = 42,
    verbose = 0
  )
)
```

## 7. Predict and Export Submission with Selected Features

```{r}
# Subset test data to selected features only
test_reduced <- smallesttest[, selected_features]

# Create CatBoost pool with reduced test features
pool_test_reduced <- catboost.load_pool(data = test_reduced)

# Load sample submission (to preserve test row structure)
sample_submission <- read.csv("sample_submission2024.csv")

# Predict class probabilities for test set using the reduced final model
probs <- catboost.predict(final_model_reduced, pool_test_reduced, prediction_type = "Probability")
colnames(probs) <- c("Ch1", "Ch2", "Ch3", "Ch4")

# Ensure prediction and submission rows match
stopifnot(nrow(sample_submission) == nrow(probs))

# Combine predictions with original 'No' column
submission <- data.frame(
  No = sample_submission$No,
  probs
)

# Save to CSV
write.csv(submission, "CatBoost_Model_Insight_Edge_Probabilities.csv", row.names = FALSE)
```